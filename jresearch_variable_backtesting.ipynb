{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimeGAN Sythetic Data Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, MeanSquaredError, MeanAbsoluteError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.saving import load_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "from backtesting import Backtest, Strategy\n",
    "from backtesting.lib import crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    print('Using GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "else:\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('time_gan_research_variable')\n",
    "hdf_store = path / 'TimeSeriesGAN.h5'\n",
    "results_path = Path('time_gan_research_variable')\n",
    "log_dir = results_path / f'experiment_{experiment:02}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 24 #window of time (days) that model uses to predict last (24th) day\n",
    "n_seq = 30 #ticker count\n",
    "batch_size = 128\n",
    "\n",
    "start_date, end_date = '2000-01-01', '2022-12-01' #ticker price data yyyy-mm-dd\n",
    "train_test_split = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pulled manually from\n",
    "#https://money.cnn.com/magazines/fortune/fortune500_archive/full/2000/\n",
    "tickers = ['GM', 'WMT', 'XOM', 'F', 'GE', 'IBM', 'C', 'T', 'MO', 'BA', \n",
    "           'BAC', 'HPQ', 'KR', 'STFGX', 'AIG', 'HD', 'PG', 'FNMA', 'CVX', \n",
    "           'MS', 'JPM', 'TGT', 'VZ', 'MRK', 'MSI', 'MCK', 'INTC', 'DD', 'JNJ', 'COST']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_data():\n",
    "    df = yf.download(tickers, start_date, end_date)['Adj Close']\n",
    "    # Preprocess the dataset:\n",
    "    scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "    data = []\n",
    "    for i in range(len(df) - seq_len):\n",
    "        data.append(scaled_data[i:i + seq_len])\n",
    "    return data, df, df.index\n",
    "\n",
    "\n",
    "real_data, yf_df, yf_index = get_real_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_windows = len(real_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sythetic Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_random_data():\n",
    "    while True:\n",
    "        yield np.random.uniform(low=0, high=1, size=(seq_len, n_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_series = iter(tf.data.Dataset\n",
    "                     .from_generator(make_random_data, output_types=tf.float32)\n",
    "                     .batch(batch_size)\n",
    "                     .repeat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data_keras = load_model(log_dir / \"synthetic_data.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(synthetic_data_keras.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#every time this is called, a new sythetic series is generated\n",
    "def generate_data():\n",
    "    generated_data = []\n",
    "    for i in range(int(n_windows / batch_size)):\n",
    "        Z_ = next(random_series)\n",
    "        d = synthetic_data_keras(Z_)\n",
    "        generated_data.append(d)\n",
    "    generated_data = np.array(np.vstack(generated_data))\n",
    "    #generated_data = (scaler.inverse_transform(generated_data.reshape(-1, n_seq)).reshape(-1, seq_len, n_seq))\n",
    "    return generated_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential([GRU(12, input_shape=(seq_len-1, n_seq)),\n",
    "                        Dense(6)])\n",
    "\n",
    "    model.compile(optimizer=Adam(),\n",
    "                  loss=MeanAbsoluteError(name='MAE'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#synthetic_data = generate_data()\n",
    "#len(synthetic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set indecies for train/test splits\n",
    "real_data = np.array(real_data)[:5632] #Length of sythetic data\n",
    "\n",
    "n_series = real_data.shape[0]\n",
    "\n",
    "idx = np.arange(n_series)\n",
    "\n",
    "n_train = int(train_test_split*n_series)\n",
    "train_idx = idx[:n_train]\n",
    "test_idx = idx[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test_data = real_data[test_idx, :seq_len-1, :]\n",
    "real_test_label = real_data[test_idx, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predictions(data, train_idx):\n",
    "    data_train = data[train_idx, :seq_len-1, :]\n",
    "    data_label = data[train_idx, -1, :]\n",
    "\n",
    "    ts_regression = get_model()\n",
    "    synthetic_result = ts_regression.fit(x=data_train,\n",
    "                                        y=data_label,\n",
    "                                        validation_data=(\n",
    "                                            real_test_data, \n",
    "                                            real_test_label),\n",
    "                                        epochs=100,\n",
    "                                        batch_size=batch_size,\n",
    "                                        verbose=0)\n",
    "    test_predict_scaled = ts_regression.predict(real_test_data, verbose=0)\n",
    "    test_predict = pd.DataFrame(scaler.inverse_transform(test_predict_scaled).squeeze())\n",
    "    return test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_predict = model_predictions(real_data, train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reverse real data back from scaler\n",
    "real_unscaled = pd.DataFrame(scaler.inverse_transform(real_test_label).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set index to dates\n",
    "real_unscaled = real_unscaled.set_index(yf_index[test_idx])\n",
    "#test_predict = test_predict.set_index(yf_index[test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_preformance(real, predict, filename):\n",
    "    ticker_count = len(tickers)\n",
    "    fig, axes = plt.subplots(nrows=ticker_count//2, ncols=2, \n",
    "                             figsize=(int(ticker_count*14/6), int(ticker_count*7/6)))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for j, ticker in enumerate(tickers):\n",
    "        (pd.DataFrame({'Real': real.iloc[:, j],\n",
    "                    'Synthetic Trained': predict.iloc[:, j]})\n",
    "        .plot(ax=axes[j],\n",
    "            title=ticker,\n",
    "            secondary_y='Synthetic', style=['-', '--'],\n",
    "            lw=1))\n",
    "    sns.despine()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(filename)\n",
    "\n",
    "#plot_preformance(real_unscaled, test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To Get our Backtestingpy strategy to work nice with different tickers\n",
    "#We have to create a new class for each ticker\n",
    "def ModelStrategy(ticker_series):\n",
    "    class ModelStrategy_Inst(Strategy):\n",
    "        percent_to_beat = 0.07\n",
    "\n",
    "        def init(self):\n",
    "            self.predict_iter = iter(ticker_series.to_numpy())\n",
    "            self.price_today = next(self.predict_iter)\n",
    "\n",
    "        def next(self):\n",
    "            price_tomorrow = next(self.predict_iter)\n",
    "            if price_tomorrow > self.price_today+self.price_today*self.percent_to_beat:\n",
    "                self.buy()\n",
    "            elif price_tomorrow < self.price_today-self.price_today*self.percent_to_beat:\n",
    "                self.sell()\n",
    "            self.price_today = price_tomorrow\n",
    "    return ModelStrategy_Inst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backtesting On Each Stock \n",
    "def backtest(prediction):\n",
    "    return_percents = [0]*len(tickers)\n",
    "    stats_dict = {}\n",
    "    bt_dict = {}\n",
    "    for idx in range(len(tickers)):\n",
    "        #YF redownload all values as needed by backtesting\n",
    "        price_df = yf.download(tickers[idx], prediction.index[0], prediction.index[-1])\n",
    "        #Initiate and optimize backtest based on best percent_to_beat value\n",
    "        bt = Backtest(price_df, ModelStrategy(prediction[idx]), commission=0.002, exclusive_orders=True)\n",
    "        stats_opt = bt.optimize(\n",
    "            percent_to_beat=np.arange(0.01, 0.1, 0.01).tolist(),\n",
    "            maximize=\"Equity Final [$]\"\n",
    "        )\n",
    "        return_percents[idx] = stats_opt[\"Return [%]\"]\n",
    "        stats_dict.update({tickers[idx]: stats_opt})\n",
    "        bt_dict.update({tickers[idx]: bt})\n",
    "    return return_percents, stats_dict, bt_dict\n",
    "\n",
    "#return_percents, stats_dict, bt_dict = backtest(test_predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_real_model = None\n",
    "best_real_return_avg = 0\n",
    "best_real_test_predict = None\n",
    "for k in range(iterations):\n",
    "    print(\"Iteration: \"+str(k))\n",
    "\n",
    "    test_predict = model_predictions(real_data, train_idx)\n",
    "    test_predict = test_predict.set_index(yf_index[test_idx])\n",
    "\n",
    "    return_percents, stats_dict, bt_dict = backtest(test_predict)\n",
    "    return_avg = np.average(return_percents)\n",
    "\n",
    "    if best_real_model==None or best_real_return_avg<return_avg:\n",
    "        best_real_model = return_percents, stats_dict, bt_dict\n",
    "        best_real_return_avg = return_avg\n",
    "        best_real_test_predict = test_predict\n",
    "        print(\"New Best With Returns: \"+str(best_real_model[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_preformance(real_unscaled, best_real_test_predict, log_dir / \"real_prediction_plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = pd.concat(stats_dict, axis=1)\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_real_model[2][\"GE\"].plot(filename=str(log_dir / \"plot_ge_real.html\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_syn_model = None\n",
    "best_syn_return_avg = 0\n",
    "best_syn_test_predict = None\n",
    "for k in range(iterations):\n",
    "    print(\"Iteration: \"+str(k))\n",
    "    generated_data = generate_data()\n",
    "\n",
    "    test_predict2 = model_predictions(generated_data, train_idx)\n",
    "    test_predict2 = test_predict2.set_index(yf_index[test_idx])\n",
    "\n",
    "    return_percents, stats_dict, bt_dict = backtest(test_predict2)\n",
    "    return_avg = np.average(return_percents)\n",
    "\n",
    "    if best_syn_model==None or best_syn_return_avg<return_avg:\n",
    "        best_syn_model = return_percents, stats_dict, bt_dict\n",
    "        best_syn_return_avg = return_avg\n",
    "        best_syn_test_predict = test_predict2\n",
    "        print(\"New Best With Returns: \"+str(best_syn_model[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_preformance(real_unscaled, best_syn_test_predict, \"syn_prediction_plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_syn_df = pd.concat(best_syn_model[1], axis=1)\n",
    "stats_syn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_real_model[2][\"GE\"].plot(filename=str(log_dir / \"plot_ge_syn.html\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jresearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
